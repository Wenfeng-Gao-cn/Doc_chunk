
llm:
  #--------------------------------------#
  # 本地Qwen-30B模型  
  # model_name: "/home/llm/models/pretrained/Qwen3-30B-A3B-FP8"
  # openai_api_key: "sk-Feb1st"
  # openai_api_base: "http://172.16.86.53:9981/v1/"
  # temperature: 0
  # streaming: true
  # model_kwargs: 
  #   "response_format": {"type": "json_object"}  # 关键：启用 JSON 模式  

  # model_name: "/home/llm/models/pretrained/Qwen3-14B"
  # openai_api_key: "sk-Feb1st"
  # openai_api_base: "http://172.16.86.52:9981/v1"
  # temperature: 0
  #--------------------------------------#
  #硅基流动
  # model_name: "baidu/ERNIE-4.5-300B-A47B" 
  # # model_name: "deepseek-ai/DeepSeek-V3"
  # openai_api_key: "sk-xucqkbqtmjyemzpumujgrtrfqmqxgapkgzmuqlrmhnyvgbhm"
  # openai_api_base: "https://api.siliconflow.cn"
  # temperature: 0
  # model_kwargs: 
  #   "response_format": {"type": "json_object"}  # 关键：启用 JSON 模式  
  #--------------------------------------#
  # DeepSeek——DeepSeek-Chat
  model_name: "deepseek-chat"
  openai_api_key: "sk-1d437538f5404275b48425bb9e761613"
  openai_api_base: "https://api.deepseek.com"
  temperature: 0
  model_kwargs: 
    "response_format": {"type": "json_object"}  # 关键：启用 JSON 模式
  #--------------------------------------#
  # 百度云千帆——百度文心ERNIE-4.5-21B-A3B
  # model_name: "ernie-4.5-21b-a3b"
  # openai_api_key: "bce-v3/ALTAK-o6dxOMYkKAAgEYvkcn5pg/d1da7609a6dfee558cdbf43386f74e04cb30897a"
  # openai_api_base: "https://qianfan.baidubce.com/v2/"
  # temperature: 0
  # model_kwargs: 
  #   "response_format": {"type": "json_object"}  # 关键：启用 JSON 模式




# 嵌入模型配置
embedding_model:
  model_name: "Pro/BAAI/bge-m3"  # 支持OpenAI模型和第三方模型
  openai_api_key: "sk-xucqkbqtmjyemzpumujgrtrfqmqxgapkgzmuqlrmhnyvgbhm"
  openai_api_base: "https://api.siliconflow.cn"  
  max_retries: 3  # 最大重试次数
  request_timeout: 60  # 请求超时时间（秒）

# STD_QA_file:
#   file_name: "XTY问题库.csv"
#   has_header: true
# Match_QA_config:
#   batch_size: 25
#   include_answers: false
#   max_retries: 3
#   max_records: 10000
#   stream_mode: false  
#   debug_logger: true

# 向量数据库配置
vectordb_config:
  persist_directory: "./chroma_db"  # 向量数据库存储目录
  collection_name: "xty_qa_collection"  # 集合名称
  batch_size: 50  # 批量处理大小
  max_records: 0  # 最大处理记录数（0表示处理所有记录）

# QA匹配配置
graph_config:
  get_k_llm: "llm"
  eva_k_llm: "llm"
  recorrect_k_llm: "llm"
  matcher_llm: "llm"  # 查找字符串是否是原文的llm
  llm_matcher_prompt: "prompt/llm_matcher_prompt.md"
  get_k_prompt: "prompt/get_k_prompt_simple.md"  # 使用简化版本的提示词
  eva_k_prompt: "prompt/eva_k_prompt.md"
  recorrect_k_prompt: "prompt/recorrect_k_prompt.md"
  eva_k_times: 2  # 执行评估知识树完整性的次数
  batch_size: 25
  include_answers: false
  max_retries: 3
  max_records: 10000
  app_stream_mode: true  # 是否使用流式处理
  debug_logger: true


# 日志配置
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_file: "create_chunk.log"
  max_file_size: "10MB"
  backup_count: 5
